{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOCKPnlP00+ujxeuEToflWC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Computer-Vision/blob/main/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.After each stride-2 conv, why do we double the number of filters?\n",
        "\n",
        "Stride controls how the filter convolves around the input volume. In the example we had in part 1, the filter convolves around the input volume by shifting one unit at a time. The amount by which the filter shifts is the stride.Stride is normally set in a way so that the output volume is an integer and not a fraction."
      ],
      "metadata": {
        "id": "EF13GWKpj447"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Why do we use a larger kernel with MNIST (with simple cnn) in the first conv?\n",
        "\n",
        "In much deeper networks these kernels could be filtering to animal features such as eyes or bird wings. Having a higher number of convolutional kernels creates a higher number of channels/feature maps and a growing amount of data and this uses more memory."
      ],
      "metadata": {
        "id": "SD9U32yfkKWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.What data is saved by ActivationStats for each layer?\n",
        "\n",
        "Simply put, an activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. When comparing with a neuron-based model that is in our brains, the activation function is at the end deciding what is to be fired to the next neuron."
      ],
      "metadata": {
        "id": "yw2dhLRGkXXr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.How do we get a learner's callback after they've completed training?\n",
        "\n",
        "When should you renew your learning license? In India, a learner's licence is valid for a period of up to 6 months. However, if the learner's licence expires, you can either opt to apply for a fresh learner's licence or renew your learner's licence through the online or offline procedures.\n",
        "\n"
      ],
      "metadata": {
        "id": "6dKQBiF2kjHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What are the drawbacks of activations above zero?\n",
        "\n",
        "Initializing all the weights with zeros leads the neurons to learn the same features during training.Thus, both neurons will evolve symmetrically throughout training, effectively preventing different neurons from learning different things"
      ],
      "metadata": {
        "id": "ftOgc4kVk0jS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Draw up the benefits and drawbacks of practicing in larger batches?\n",
        "\n",
        "Using a batch size of 64 (orange) achieves a test accuracy of 98% while using a batch size of 1024 only achieves about 96%. But by increasing the learning rate, using a batch size of 1024 also achieves test accuracy of 98%"
      ],
      "metadata": {
        "id": "fP1NF05ClEg6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Why should we avoid starting training with a high learning rate?\n",
        "\n",
        "If your learning rate is set too low, training will progress very slowly as you are making very tiny updates to the weights in your network. However, if your learning rate is set too high, it can cause undesirable divergent behavior in your loss function."
      ],
      "metadata": {
        "id": "zGkQDJWNlRFz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What are the pros of studying with a high rate of learning?\n",
        "\n",
        "Faster and simpler process - Computer vision systems can carry out repetitive and monotonous tasks at a faster rate, which simplifies the work for humans. Better products and services - Computer vision systems that have been trained very well will commit zero mistakes"
      ],
      "metadata": {
        "id": "p-RtSrHhlZ9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Why do we want to end the training with a low learning rate?\n",
        "\n",
        "Generally, a large learning rate allows the model to learn faster, at the cost of arriving on a sub-optimal final set of weights. A smaller learning rate may allow the model to learn a more optimal or even globally optimal set of weights but may take significantly longer to train"
      ],
      "metadata": {
        "id": "aOFZ_7oSltFq"
      }
    }
  ]
}