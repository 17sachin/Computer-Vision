{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORaG8aE/ikgPfDuCQq9Pyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/17sachin/Computer-Vision/blob/main/Assignment_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Describe the Quick R-CNN architecture.\n",
        "\n",
        "The Fast R-CNN consists of a CNN (usually pre-trained on the ImageNet classification task) with its final pooling layer replaced by an “ROI pooling” layer and its final FC layer is replaced by two branches — a (K + 1) category softmax layer branch and a category-specific bounding box regression branch."
      ],
      "metadata": {
        "id": "0h_ejH-B7OCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Describe two Fast R-CNN loss functions.\n",
        "\n",
        "Faster R-CNN is a deep convolutional network used for object detection, that appears to the user as a single, end-to-end, unified network. The network can accurately and quickly predict the locations of different objects."
      ],
      "metadata": {
        "id": "VarOYLFT7VWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Describe the DISABILITIES OF FAST R-CNN"
      ],
      "metadata": {
        "id": "bI2QUCwW7dWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Describe how the area proposal network works.\n",
        "\n",
        "A Region Proposal Network, or RPN, is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals."
      ],
      "metadata": {
        "id": "3HfN1NgE7rMM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Describe how the RoI pooling layer works.\n",
        "\n",
        "ROI pooling solves the problem of fixed image size requirement for object detection network. RO I pooling produces the fixed-size feature maps from non-uniform inputs by doing max-pooling on the inputs. The number of output channels is equal to the number of input channels for this layer."
      ],
      "metadata": {
        "id": "jE5859ZN72OL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.What are fully convolutional networks and how do they work? (FCNs)\n",
        "\n",
        "Fully convolutional indicates that the neural network is composed of convolutional layers without any fully-connected layers or MLP usually found at the end of the network. A CNN with fully connected layers is just as end-to-end learnable as a fully convolutional one.\n",
        "\n",
        "FCN is a network that does not contain any “Dense” layers (as in traditional CNNs) instead it contains 1x1 convolutions that perform the task of fully connected layers (Dense layers).Building a fully convolutional network (FCN) in TensorFlow using Keras."
      ],
      "metadata": {
        "id": "1HdDW84B798S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What are anchor boxes and how do you use them?\n",
        "\n",
        "Anchor boxes are a set of predefined bounding boxes of a certain height and width. These boxes are defined to capture the scale and aspect ratio of specific object classes you want to detect and are typically chosen based on object sizes in your training datasets."
      ],
      "metadata": {
        "id": "Ybposabm8LO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Describe the Single-shot Detector&#39;s architecture (SSD)\n",
        "\n",
        "SSD is a single-shot detector. It has no delegated region proposal network and predicts the boundary boxes and the classes directly from feature maps in one single pass. To improve accuracy, SSD introduces: small convolutional filters to predict object classes and offsets to default boundary boxes."
      ],
      "metadata": {
        "id": "qbcm0V-v8UWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.HOW DOES THE SSD NETWORK PREDICT?\n",
        "\n",
        "SSD uses a matching phase while training, to match the appropriate anchor box with the bounding boxes of each ground truth object within an image.This property is used for training the network and for predicting the detected objects and their locations once the network has been trained."
      ],
      "metadata": {
        "id": "JqSy3Lee8bab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.Explain Multi Scale Detections?\n",
        "\n",
        "A unified deep neural network, denoted the multi-scale CNN (MS-CNN), is proposed for fast multi-scale object detection.In the proposal sub-network, detection is performed at multiple output layers, so that receptive fields match objects of different scales."
      ],
      "metadata": {
        "id": "Xsbp5UWu8jgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.What are dilated (or atrous) convolutions?\n",
        "\n",
        "Dilated Convolutions are a type of convolution that “inflate” the kernel by inserting holes between the kernel elements. An additional parameter (dilation rate) indicates how much the kernel is widened. There are usually spaces inserted between kernel elements."
      ],
      "metadata": {
        "id": "LUAdGCwy8rXS"
      }
    }
  ]
}